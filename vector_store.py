import faiss
import pandas as pd
from sentence_transformers import SentenceTransformer
import numpy as np

# ğŸ”¹ à¹‚à¸«à¸¥à¸” BERT Model à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸£à¹‰à¸²à¸‡ Embeddings
model = SentenceTransformer("sentence-transformers/bert-base-nli-mean-tokens")

# ğŸ”¹ à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Web Scraping
df = pd.read_csv("scraped_data.csv")
texts = df["content"].tolist()

# ğŸ”¹ à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ Embeddings
embeddings = model.encode(texts)

# ğŸ”¹ à¸ªà¸£à¹‰à¸²à¸‡ FAISS Index
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings, dtype=np.float32))

# ğŸ”¹ à¸šà¸±à¸™à¸—à¸¶à¸ Index
faiss.write_index(index, "faiss_index.bin")
print("âœ… FAISS Index à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸³à¹€à¸£à¹‡à¸ˆ!")
